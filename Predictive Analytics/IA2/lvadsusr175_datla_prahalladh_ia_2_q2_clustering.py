# -*- coding: utf-8 -*-
"""LVADSUSR175_Datla_Prahalladh_IA_2_Q2_CLUSTERING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YGT6nKyD231gfHiIt_6TUKcK6qcrP1qL
"""

import pandas as pd
df = pd.read_csv("/content/Mall_Customers.csv")
df

df.head(5)

df.info()

df.describe()

df.isnull().sum() #Null Values only in Annual Income

df.duplicated().sum() # No duplicates

df["Gender"].value_counts()

# EDA
# Univarite Analysis
import matplotlib.pyplot as plt
import seaborn as sns
# Plot histograms for numerical columns
for column in df.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 5))
    sns.histplot(df[column])
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.show()

# Plot bar charts for categorical columns
for column in df.select_dtypes(include=['object']).columns:
    plt.figure(figsize=(10, 5))
    df[column].value_counts().plot(kind='bar')
    plt.title(f'Bar Chart of {column}')
    plt.xlabel(column)
    plt.ylabel('Count')
    plt.show()

# Correlation
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
# Compute the correlation matrix for numerical variables
correlation_matrix = df[numerical_columns].corr()
print("Correlation matrix:\n", correlation_matrix)


# Plot the correlation matrix as a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

# Outliers

numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
for i in range(len(numerical_columns)):
    for j in range(i + 1, len(numerical_columns)):
        plt.figure(figsize=(10, 6))
        sns.scatterplot(data=df, x=numerical_columns[i], y=numerical_columns[j])
        plt.title(f'Scatter Plot between {numerical_columns[i]} and {numerical_columns[j]}')
        plt.show()

# Endoing
df["Gender"].replace({"Male":0,"Female":1},inplace =True)

df.info()

# Null Values
df["Annual Income (k$)"].fillna(df["Annual Income (k$)"].mean(),inplace = True)

df["Gender"].value_counts()

#Scaling using StandardScaler
from sklearn.preprocessing import StandardScaler
Scaled = StandardScaler()
# Only be using Annual Income and Spending Score
c=['Annual Income (k$)',	'Spending Score (1-100)']
df[c]=Scaled.fit_transform(df[c])

scaled_features=Scaled.fit_transform(df[c])

# Elbow method
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
inertia_score=[]
for i in range(1,8):
    kmeans=KMeans(n_clusters=i,random_state=20)
    kmeans.fit(scaled_features)
    inertia_score.append(kmeans.inertia_)

#plot the elbow curve
plt.figure(figsize=(15,8))
plt.plot(range(1,8),inertia_score,marker='o')
plt.show()

from sklearn.cluster import KMeans

num_clusters = 5
kmeans = KMeans(n_clusters=num_clusters, random_state=42)
df['cluster'] = kmeans.fit_predict(scaled_features)

plt.figure(figsize=(10,6))
sns.scatterplot(x='Annual Income (k$)',y = 'Spending Score (1-100)',hue='cluster',palette=['green','red','blue','black','yellow'],legend=True,data=df)
plt.xlabel("Annual Income")
plt.ylabel("Spending Score")
plt.show()

silhouette_score(df, df['cluster'] )