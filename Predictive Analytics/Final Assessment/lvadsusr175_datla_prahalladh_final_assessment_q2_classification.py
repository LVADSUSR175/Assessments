# -*- coding: utf-8 -*-
"""LVADSUSR175_Datla_Prahalladh_Final_Assessment_q2_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IPyiwV3FtDphVufWAKL579-UwFC0QvMy
"""

import pandas as pd
df = pd.read_csv("/content/penguins_classification.csv")
df

df.head(5)

df.columns

df.info()

df.shape
df.describe()

df.isnull().sum() # checking for null values
# 8 Null Values in bill_depth_mm

df.duplicated().sum() # checking for duplicate values
# No duplicates

# We can proceed to EDA
#EDA
# Univariate Analysis
# Plot histograms for numerical columns
import matplotlib.pyplot as plt
import seaborn as sns
for column in df.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 5))
    sns.histplot(df[column])
    plt.title(f'Histogram of {column}')
    plt.xlabel(column)
    plt.ylabel('Frequency')
    plt.show()

# Plot bar charts for categorical columns
for column in df.select_dtypes(include=['object']).columns:
    plt.figure(figsize=(10, 5))
    df[column].value_counts().plot(kind='bar')
    plt.title(f'Bar Chart of {column}')
    plt.xlabel(column)
    plt.ylabel('Count')
    plt.show()

df["island"].value_counts()

df.info()

#Correlation Analysis
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
# Compute the correlation matrix for numerical variables
correlation_matrix = df[numerical_columns].corr()
print("Correlation matrix:\n", correlation_matrix)

# Plot the correlation matrix as a heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Heatmap of Correlation Matrix')
plt.show()

# scatter plot
# Generate scatter plots for pairs of numerical variables
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
for i in range(len(numerical_columns)):
    for j in range(i + 1, len(numerical_columns)):
        plt.figure(figsize=(10, 6))
        sns.scatterplot(data=df, x=numerical_columns[i], y=numerical_columns[j])
        plt.title(f'Scatter Plot between {numerical_columns[i]} and {numerical_columns[j]}')
        plt.show()

# Outliers
# Identify numerical columns by data type
numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns

# Create a box plot for each numerical column
for column in numerical_columns:
    plt.figure(figsize=(10, 6))  # Set the figure size for better readability
    sns.boxplot(x=df[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()
# As we can see from the boxplot there are very few outliers # Ignoring them

df["bill_depth_mm"].value_counts()

# feature Engineering
# Removing Null Values
df["bill_depth_mm"].fillna(df["bill_depth_mm"].mean(),inplace = True)


# No Duplicates
df.info()
# we have two columns in object type encoding them
from sklearn.preprocessing import LabelEncoder
len=LabelEncoder()
for column in df.select_dtypes(include=['object']):
    df[column]=len.fit_transform(df[column])

df.info() # All columns are in Numerical
df.isnull().sum()

# Model Training and Testing
X = df.drop(columns =["species"])
Y = df["species"]

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=40)


from sklearn.preprocessing import MinMaxScaler,StandardScaler
scaler = MinMaxScaler()
X_train=pd.DataFrame(scaler.fit_transform(X_train[list(X.columns)]),
                                    columns=X.columns)
X_test=pd.DataFrame(scaler.transform(X_test[list(X.columns)]),
                                    columns=X.columns)

X.isnull().sum()

#Model and evaluation Metric
from sklearn import tree
model = tree.DecisionTreeClassifier()
model.fit(X_train,Y_train)
Y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score,classification_report
accuracy = accuracy_score(Y_pred,Y_test)
print("Model Prediction Accuracy: %.2f%%" % (accuracy * 100.0))

cr=classification_report(Y_pred,Y_test)
print(f"Classification report:\n {cr}")

# Separate Evaluation Metric
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
accuracy = accuracy_score(Y_test, Y_pred)
precision = precision_score(Y_test, Y_pred, pos_label=1)
recall = recall_score(Y_test, Y_pred, pos_label=1)
conf_matrix = confusion_matrix(Y_test, Y_pred)

print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print("******************************************************")
plt.title("Confusion Matrix")
sns.heatmap(conf_matrix,annot=True)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')